{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Explore models\n",
    "Try SOTA text summarization models for their performance on speech/lecture transcripts\n",
    "Since Sat. Oct. 23rd, 2021\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "## Setup\n",
    "import torch\n",
    "# import tensorflow\n",
    "from transformers import pipeline\n",
    "\n",
    "from util import *\n",
    "\n",
    "\n",
    "txt = get_ted_eg()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## BigBird\n",
    "\"Big Bird: Transformers for Longer Sequences\".\n",
    "Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.\n",
    "*NeurIPS 2020*.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 12 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3.Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we present a new']\n"
     ]
    }
   ],
   "source": [
    "def distill_bart():\n",
    "    \"\"\"\n",
    "    Default: `sshleifer/distilbart-cnn-12-6` in pytorch\n",
    "    \"\"\"\n",
    "    summarizer = pipeline('summarization')\n",
    "    summarizer(txt, min_length=50, max_length=200)  # Too much tokens than maximum of 1024\n",
    "\n",
    "\n",
    "def t5():\n",
    "    \"\"\"\n",
    "    `t5` in tf\n",
    "    \"\"\"\n",
    "    summarizer = pipeline('summarization', model='t5-base', tokenizer='t5-base', framework='tf')\n",
    "    summarizer(txt, min_length=5, max_length=20)\n",
    "\n",
    "\n",
    "def bigbird():\n",
    "    \"\"\"\n",
    "    `BigBird` in torch\n",
    "\n",
    "    Looks like doesn't suppport summarization\n",
    "    \"\"\"\n",
    "    summarizer = pipeline(\n",
    "        'summarization',\n",
    "        model='google/bigbird-roberta-base',\n",
    "        tokenizer='google/bigbird-roberta-base'\n",
    "    )\n",
    "    summarizer(txt, min_length=5, max_length=20)\n",
    "\n",
    "\n",
    "def bigbird_pegasus():\n",
    "    from transformers import PegasusTokenizer, BigBirdPegasusForConditionalGeneration, BigBirdPegasusConfig\n",
    "\n",
    "    model = BigBirdPegasusForConditionalGeneration.from_pretrained('google/bigbird-pegasus-large-arxiv')\n",
    "    tokenizer = PegasusTokenizer.from_pretrained('google/bigbird-pegasus-large-arxiv')\n",
    "\n",
    "    ARTICLE_TO_SUMMARIZE = \"My friends are cool but they eat too many carbs.\"\n",
    "    inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=4096, return_tensors='pt', truncation=True)\n",
    "\n",
    "    # Generate Summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=5, early_stopping=True)\n",
    "    print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])\n",
    "\n",
    "\n",
    "def bigbird_pegasus_():\n",
    "    from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
    "\n",
    "    # by default encoder-attention is `block_sparse` with num_random_blocks=3, block_size=64\n",
    "    model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n",
    "    # model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\", attention_type=\"original_full\")\n",
    "    # model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\", block_size=16, num_random_blocks=2)\n",
    "\n",
    "    text = \"haha\"\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    prediction = model.generate(**inputs)\n",
    "    prediction = tokenizer.batch_decode(prediction)\n",
    "\n",
    "# bigbird()\n",
    "bigbird_pegasus()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}