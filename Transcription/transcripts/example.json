{"transcription": [{"transcript": "No, you don't need a reason.", "confidence": 0.7614100575447083}, {"transcript": " Apple TV.", "confidence": 0.9259675741195679}, {"transcript": " All right. Apple TV. Sweet don't have to carry around a dongle.", "confidence": 0.862675130367279}, {"transcript": " Welcome, welcome everybody.", "confidence": 0.9876291155815125}, {"transcript": " Yeah, it's um the gloomy day. I got a bunch of great emails saying I can't make it. I feel it. I feel it. But anyway, let's just jump right into how many people have groups?", "confidence": 0.9300932288169861}, {"transcript": " Awesome. That's all you left. The scene. Pretty much everybody. So we'll will tease out who made who may not have a group and reach out to you. So, I didn't get an email from anyone, you know, that needs further assistance with getting their group sorted but", "confidence": 0.9332259297370911}, {"transcript": " Google, what is a real good job everybody. Getting those submissions in. Its it's some of the easiest points you can get. So", "confidence": 0.9279049038887024}, {"transcript": " So today we're going to be talking about a couple things, right? Like, so now you have groups, okay, and remember this class, the primary thing is about creating something awesome in a team, developing a solution to the prop to a problem. End-to-end being thoughtful about design, being thoughtful about implementation, architecting, the solution implementing the solution and then delivering it. I'm presenting about those Solution. That's what this experience is from primarily, focused on. And so, now, with your groups in hand and perhaps some project ideas at the ready. Where can I where can I jump into that face? So I want to talk a little bit about the to landscape and this is remember this is a very open-ended kind of Journey, right? Imagine that your group is a little start-up or a little project team. You do many, large companies will create these these project teams to go often innovate.", "confidence": 0.9711287021636963}, {"transcript": " Innovation lab. And so it's really, it's a journey that starts with understanding how you're going to approach that problem solution. And what are the tools that you're going to bring some beer on that? So we'll just talk about the to landscape and this is just a suggestion. Anything you find out there. I'm interested to learn about what you're excited about using a saddle. So we'll have our on Monday. We'll have half the teams present the few slides of the idea and then get some real time reaction. And then on Wednesday, we'll have a few flies from the second batch of groups on the project ideas and reaction and they're due on Friday.", "confidence": 0.956702709197998}, {"transcript": " so,", "confidence": 0.8860632181167603}, {"transcript": " That sucks coming up and we'll talk about that a good bit. And then we're going to just jump in and pick up where we left off last time. Now. I've gotten a couple interesting emails. Thank you so much. Like I can sense. There's a little like", "confidence": 0.9465414881706238}, {"transcript": " A little nervousness about reading papers. And you know what, what? This is a New Journey from many folks, right at the idea of reading, an academic research paper and that's coming coming soon. And I wanted to emphasize, by the way, you know, when I have new graduate students, PhD students that are joining the PHD program.", "confidence": 0.9326996803283691}, {"transcript": " Bill Bill asked me, there's this expectation. Is this an eight expectation that you're supposed to be able to read a paper and understand it? And what all quickly tell him in this. There's some, you know,", "confidence": 0.920876145362854}, {"transcript": " Dissonance around that. And what I'll tell him is, dude, you have to read a hundred research papers on till you can feel like you can read research papers, right? That's the journey actually grad school, 50% of it is getting that skill up, right? So this is much of, it's a journey of, you'll have your first toe in the water and then you leave paper after paper, and you're only going to get through maybe 10 papers in his class. Right? And so you should get familiar with the what they look like, how their design, how they make their claims. And it's not the expectation that you're not to be tested on what your understanding of the paper. This is a journey 2", "confidence": 0.9651539325714111}, {"transcript": " Get in there and understand and be able to talk and inhale, the latest and greatest of what's going on. And this is your first in roads. So, this is definitely an effort based thing. Right? This is one of the be on the Project's, almost everything else in this class has an a for effort if you're engaged and you're trying, you're succeeding because that's a journey of Discovery and that's actually what happens, right? A perseverance and I'm putting your energy into things that matter things that are valuable. So, that's good, right?", "confidence": 0.9478186964988708}, {"transcript": " Are tools of the trade? Okay. So what are we going to be doing these groups? We have our group's not? What are we doing? All right, cool. So I talked a little bit about it. But more practically. We're going to be building something like this. Right? We're going to be using speech recognition in some cases and other cases. You won't need to a, sorry. You'll just say, I want to do. It's a pot. So it should be, it'll be a text. That's up to you for the problem that you so choose to Endeavor. So you'll have to speak up and there's a swath of ways you can approach this. And we'll talk about kind of like lean heavy on the Moor.", "confidence": 0.9337457418441772}, {"transcript": " You know, the more kind of pulled up way you can kind of go and do things from scratch and Tinker with models, which a lot of folks I know are going to want to do cuz that's what happened or you can kind of stay inside a to system. But see what Microsoft offers and what what Google offers and what what else out there to help me build this experience that I want to create in the world, but you're going to be understanding what was said and then you're going to have some code responsible for doing stuff processing that understanding solving the problem on that critical path. So primarily will be designing some of this stuff.", "confidence": 0.9726731181144714}, {"transcript": " Don't forget the of the state of the world today on this dream.", "confidence": 0.7378994822502136}, {"transcript": " Sr is a commoditized solution in deed. Does not a ton of", "confidence": 0.744682788848877}, {"transcript": " changes that are happening to the fundamental way that the science doesn't use on indeed Google. Did the last big, I would say when I, we actually Quantified at one point all of the speech-to-text systems in existence that we could find and we found Google was actually the best and there's actually some papers out there that describe what they do in production as of late. And they made the last Innovations there, right there actually injecting noise in the date of thought. So, if I have date of each of you guys talkin, I can take that data and I can superimpose ambient bus noises ambient traffic noises and Vian. I don't know if you're in the jungle, you might hear some like lions roaring, our like whatever kind of Ambia, so they were so that it can hear.", "confidence": 0.9680601954460144}, {"transcript": " So this is pretty salt and what it looks like is when you use your iPhone or your or your Android phone.", "confidence": 0.9398022294044495}, {"transcript": " There's standard fdk stuff for Speed. It's like, you know, how there's like your standard library for, I don't know everything. Let it choose something or the files. We have standardized libraries for speech to text in mobile devices. And that spans both devices really with your phones and so forth, but also like you're at home devices in your browser. There's a standardized, every browser has a standardized toolkit for speech-to-text. If you're in Chrome, you can use their standard and you look at this like you can you can put a you can have a voice interface to any website because the browser support it as a standard Chrome, Heather Sanders, Safari has their standard", "confidence": 0.9506815075874329}, {"transcript": " From using Google. Stop Safari. Interesting, but its services and so forth to get it. And I have to stay in commercial land flow and Amazon. Blacks at Microsoft Lewis. No systems pretty much work the same way under kind of terrible, but they are actually very popular and you can actually mix and match tools one. Great model for mixing mastering tools is", "confidence": 0.9379097819328308}, {"transcript": " Your business logic can take inputs from say, business logic. Just music your application. Once it understands you and what your application and take inputs from your dialogflow are your Amazon Lex, the common things you can go to Amazon to build conversation way, Iowa. I think it also take input from your own torch library, right? So you can run you can see the outputs from like dollar closing that's going to be useful to know what to do. But let me look at some outputs from some bottles that I created to do other cool stuff so you can mix and match the engines. You wanted. It was fear software. I'm not gives you a lot of flexibility to be creative and solve problems. And this is going to be probably pretty. There's not a lot of fancy energy that happens because you don't want to use a lot of deep learning for an LG Commercial Landscaping, the tool sets out there.", "confidence": 0.96867835521698}, {"transcript": " You'll probably have more algorithmic ways to determine how to respond. This is kind of interesting research home base to write. So they'll be a whole bunch of tools. You may use for natural language understanding and then text to speech is also this standardized thing that all those platforms. Do, you know, when you do text to speech on your iPhone, it sounds like Siri talking to you or one of the variations of Siri. There's like a British Siri, that's a nail and then there's like an Australian Siri.", "confidence": 0.9444667100906372}, {"transcript": " So we're just going to look at some of these tools in this slide deck is actually a resource to you actually see how you could download this lie back and decide that cuz going to have like a little map to all the stuff we talked about today, which will be a reference as you get on the Journey of thinking about your project. But this is let me just emphasize. This is a this is just to encourage exploration. It's not by any means guidelines or a specification of what you should use to keep that in mind. This is just if you want to get started on your Google Journey cuz that's how we solve problems today, without a browser on search right next to them.", "confidence": 0.9395941495895386}, {"transcript": " I know, I know, I just thought you used to have but not like, seriously. I just don't code unless, you know, whatever. So yeah, it's going to be going on that while Journey. This is a useful useful. It's in the cloud so you can just send files to it or stream wav files to it and it'll give you tax back real time.", "confidence": 0.9266022443771362}, {"transcript": " That's one. Good place to look to see what's out there. They also have a whole like", "confidence": 0.9208644032478333}, {"transcript": " You'll see all of these Cloud providers will have their ml.", "confidence": 0.9749952554702759}, {"transcript": " Suite of cloud apps and you can get models, train models, use models. And so we had a wonderful project 1 year or where", "confidence": 0.8834019303321838}, {"transcript": " they were.", "confidence": 0.9876290559768677}, {"transcript": " They were identifying.", "confidence": 0.9876291155815125}, {"transcript": " Folks, use that use computer vision to tell people's emotions while you talk to it. So you were talking to this AI it was doing and all you and it was telling your emotions and it could tell your age and I can tell your gender I think until you're all kinds of stuff. This model has like a Microsoft Vision model that's out there and they'd hooked into that API, so you'll find those.", "confidence": 0.954099714756012}, {"transcript": " This is kind of Google's offerings. Do you want to build a conversational AI system? They give you dialogflow, which is the EE from them for building chat box or virtual assistant API, right? You can plug things into it. It can interact with whatever software tools and it's all kinds of great guys, but this would be a great place to look at on that, on that Journey.", "confidence": 0.9421969652175903}, {"transcript": " So there's lots of documentation. This weather looks like this is like last year. There's actually a new MX and CX.", "confidence": 0.8262737989425659}, {"transcript": " Seahawks is like new one anyway, so it might be different but there's lots of resources out there.", "confidence": 0.882357656955719}, {"transcript": " And then there's all kinds of YouTube is awesome for this to there's all kinds of videos about how to get started with these things.", "confidence": 0.9053608179092407}, {"transcript": " So let me play this. I think it's like a minute.", "confidence": 0.8491818904876709}, {"transcript": " Why can't you deconstructing chatbots? I'm Priyanka Ricotta. And in this episode, we will dissect. The architectural to better understand the building glass.", "confidence": 0.911888062953949}, {"transcript": " five minutes when I get to watch the whole thing, but", "confidence": 0.7892259955406189}, {"transcript": " Yeah.", "confidence": 0.8101407885551453}, {"transcript": " Powered by natural language understanding to facilitate, which and natural conversation.", "confidence": 0.8296037912368774}, {"transcript": " Look at a high-level architecture.", "confidence": 0.8463598489761353}, {"transcript": " kind of clothes that's in the middle of the sky looking interface with all the common channels, including", "confidence": 0.7296542525291443}, {"transcript": " Website apps for this is the stuff they give you like nothing. You can find infinity. Have all these multi-channel wherever they are coming from where you can plug it in here. You'll find a lot of guidance on your journey, depending on what you choose to use at all. So you can always connect with me and tell if you wanted to map your project to tools. I'm happy to help and have a conversation about that. So there's a lot of resources there on the apis. This is what I was talking about in their Cloud. You can video, you know, all kinds of tools to get you up and running and tons of documentation. A cool thing is they're getting started stuff. They're simple stuff.", "confidence": 0.9421082735061646}, {"transcript": " It's not a lot of cold right to get the basic scaffolding up so that you could build your solution and we can walk through all of that on a guided tour. Enterprise might run into hiccups Amazon, has their Computing stuff Amazon voice. That sounds like, this is another interesting problem. How can you sound as human as possible? And there's many, many solutions are there. You don't have to use that stuff. You can use our demo Union, speech to text, my brother, your Java Script. What's a its reactor angular or of you or any of those cast aspersions to Angela regulars, fine to. Thank you, Google.", "confidence": 0.9617795944213867}, {"transcript": " Or somewhere, which is running a Java. I mean,", "confidence": 0.9004464745521545}, {"transcript": " alright. Okay, cool. I'll slow it down a little bit. I got to remember. I'm 85.", "confidence": 0.8615525364875793}, {"transcript": " Okay. Okay. So you got your kind of generally. If your group. It's all good. Just connect and then we'll talk about that Journey. But let's assume you wanted to do a browser delivered experience. Anything are you use JavaScript write? And thank you. Just playing job script or their deeds to their these two kids, like we act, which is awesome. And angular and view the day after, like, the three big ones, really interesting. But right, so you can use something on the front and the back. Then let's say you wanted to hook him. You wanted to just grab yourself a burnt model.", "confidence": 0.9488576650619507}, {"transcript": " Right? And you wanted to play with Burt. You want burn to do something interesting. On in your project. You can get from tensorflow Hub. Like the models out there papers with code. All the code is out there. So you can grab a burke. You can wrap it in a flask app and flasks is a, it's like us, very simple library in in Python. It's like a, it's a library for making a micro service so that you have something that's listening on a port. Right? And so your website can connect to your localhost port 8080 or whatever. And then port 8080 is your Python program. Thank you. Flask import flask done, right? There's like Fifty lines of code for like getting started was super, super easy, but we'll look at it together. Typically what I do and we'll get on a zoom call and then go look at every step together. If this is something that the group really wants to do.", "confidence": 0.9797999262809753}, {"transcript": " I'm going to introduce you to all this new stuff that I want to use and I'm like heck yeah, that's awesome to see most excited about this project is all fair game with creating mobile apps like an IOS app on an Android app. Okay. Good. I'm your old. Another opportunity. You can also create something that runs on Alexa or runs on Google home. Google home is actually very friendly to customisation and plugging into their API. So you can actually set up your flask.", "confidence": 0.9597078561782837}, {"transcript": " Go to Bojangles higher learning curve, python thing running on a server. That talks directly to your Google home in your house. So you can be like, hey, I want to talk to my 498, right? So the world's your oyster. Okay, kind of Library. Ecosystem for conversational AI. It's an interesting entry in the market and they're doing some interesting stuff. Like a lot of big companies are up taking Raza the Builder, in-house conversational AI capabilities. If you wanted to look at the open-source, you know.", "confidence": 0.9645702838897705}, {"transcript": " Linux for this stuff, right? What's the open-source ecosystem is? It's all new to everyone. Before I got this videos. You can just watch this one hour video and then you go from Soup To Nuts, building a chatbot. The literally, you can watch this one hour video if you want to do and then", "confidence": 0.934799313545227}, {"transcript": " Just Build Your solution, using what you've learned from this one on video videos.", "confidence": 0.8400338888168335}, {"transcript": " You can use the slide offline to look at some of that stuff. We've got, there's this one does pandorabots. There's all kinds of options out there. If you wanted to look probably at the tools out there. Such a disappointment is crazy. I don't know. But they had Bob Dylan, but then their solution is not awesome, but you can explore it right for yourself.", "confidence": 0.9547609686851501}, {"transcript": " So any questions on the tools or how to navigate that navigate to Logistics the tactics, go ahead.", "confidence": 0.9408766627311707}, {"transcript": " They cost money so you can avoid tools that cost money. And if there's a tool you want to use that cost money. Hit me up. I don't mind paying for it. Right? Don't worry, you're good there but is actually free and the sdks in the browser. All that stuff is free and open the models. Almost every model. I talk about this all the time with people, almost every model you can find in like Google's AI Cloud ecosystem, and like Amazon's Cloud 9 ml to look at making all the birds Roberta distill Bert Ernie.", "confidence": 0.9569692611694336}, {"transcript": " And it's like obliterating birth performance and you can get all the code and you can grab that code put in your, in your python. It's like an import torch import Transformers library and then just use that model that I just downloaded and it's better than the stuff in the cloud. So so there is no requirement to use the paint stuff. What do you get from the pizza? I don't know. More documentation. I guess maybe a customer service line you can call.", "confidence": 0.9624884128570557}, {"transcript": " It's like so easy to do groundbreaking products in this market. It's so easy. If you understand what I'm going to beat you in this class, but we are learning in this class, is going to send this stuff. You can go out there and gauge the ml world and then you can build products that are 5-10 years ahead of you. Google, Microsoft, apples excetera without a doubt, right? It's crazy. Did you know?", "confidence": 0.9457327127456665}, {"transcript": " Do you know how much?", "confidence": 0.9855571985244751}, {"transcript": " Google pays for an engineer that has like ground like state-of-the-art ml background.", "confidence": 0.9524421095848083}, {"transcript": " So there is a an engineer that from Canada. I can't remember his name. He was a professor at so it's not super far but like some papers and cool stuff, but Google pay 500 bass. Unlike.", "confidence": 0.9366666674613953}, {"transcript": " 2 million in stock for your vest stock, just to join Google for folks that know how to wield the stuff.", "confidence": 0.8877208232879639}, {"transcript": " If you engage his class and you go to a job interview, and you can recount the specifics of what you've accomplished in. This class, you are on the top of the market. I interview people Everyday, by the way guys that come with TVs, that's a data science and ML and all this stuff.", "confidence": 0.9401167035102844}, {"transcript": " I cannot impress upon you how a lot of stuff is made up in the market. Doesn't like almost everybody says data scientist when they like watch 3 videos on YouTube. I kid you not. I need to go to ask him. What they've done with the largest bass they worked in and you'll hear it feel to be describing the tutorial. Like, that's all they describe. It's just nuts. And so, I'll tell you, you will have to build us. You'll be actually the most competitive, the dream Talent that's companies want, and I will make you so excited about this class. I think it's a big deal, but I used to because I looked at the papers and the papers were from 2020 and they dominated everything else. And so I actually use the absolute City. Our train is fine-tuned.", "confidence": 0.9620216488838196}, {"transcript": " You look fine, tuning isn't zero, shot learning and all this craziness.", "confidence": 0.8063949942588806}, {"transcript": " I'm like a bird slowed.", "confidence": 0.9532443881034851}, {"transcript": " So awesome. So we have the presentations next week, right? And so,", "confidence": 0.9507730603218079}, {"transcript": " Basically, it's a couple size I have demo is a fly's here. Is you really only need? Maybe you can accomplish this in 6th and 69 slides for the whole group. But there's no there's no limit at other than the time limit. The only have like 10 to 15 minutes to present your pitch and then you're good Monday and Wednesday. We're going to have two batches by Wednesday this week. You'll know which batch you're in. Everybody wants to be in the Wednesday back. So I got it like just do it randomly if that's okay. Like, you know that it's relatively flax. If you have a real reason that you may not be able to you know, you need extra time to let me know, an email and I will sort it out with you guys.", "confidence": 0.9643957614898682}, {"transcript": " People get very anxious about. These slides are due by end of next week and the write-ups do at the end of next week. So next Friday, any questions on that.", "confidence": 0.9348927736282349}, {"transcript": " Right, right. So yeah, so typically what happens is in the presentation, this little bit of evolution that happens, right? So there's a little bit of feedback that goes on and then the right I'm still don't usually happen until after the presentation. It's one page. I'll show you what it looks like. So it's it's it's a journey that you take the feedback from the presentation and then you finalize the deck to turn it in.", "confidence": 0.9389461874961853}, {"transcript": " Any other questions?", "confidence": 0.9825270771980286}, {"transcript": " It's a mixture of both, right? It's really a judgment call. Like it's what's a qualitative scoring.", "confidence": 0.9548023343086243}, {"transcript": " You do not if you put effort and you don't have to worry. Okay, if you're engaged you don't have to worry because it's a conversation to me, right? Let's talk. And so, you know, if if you if you know put an effort and it's interesting, you'll do. Well, I don't want to give you guys a sense that", "confidence": 0.9568206667900085}, {"transcript": " see, this is a very tricky line to walk as a as an instructor cuz", "confidence": 0.903337836265564}, {"transcript": " If I tell you all that.", "confidence": 0.9876289963722229}, {"transcript": " It's relatively straightforward to do well then you won't give it as much as you would. If I was like, oh, yeah. I really I'm going to be looking for a frosty but the reality is I haven't had a group bombies. I just haven't had it, right? And so,", "confidence": 0.9680495262145996}, {"transcript": " This is tough to do especially with a larger class. What I'm going for is for you to love your work. That's it. I'm so I'm really looking for engagement engagement. Means you care about what you're doing. That's it. So when you come and present what I would love to see is that you're connected to your work, right? And you're not just going through the motions. That's it and it'll come out. So don't worry like have fun with. This is my point have fun with this. Don't stress about how you'll do. If there's an issue, come talk to me. It's very easy like reason at all. So", "confidence": 0.960300624370575}, {"transcript": " Anyway, any other questions?", "confidence": 0.8712437152862549}, {"transcript": " Is that helpful? Does that make sense quality write up complete and clearly written, right? So, you know, that's what you're shooting for our for goodness and general notion of goodness, right?", "confidence": 0.9261813759803772}, {"transcript": " Natto, Gohan.", "confidence": 0.8918100595474243}, {"transcript": " I expect changes all the way through this things are so fluid. Right? Like what you feel is right and then we'll navigate to a good scope that makes sense. These projects always change until the final presentation. I've never seen the final presentation map. Exactly to the ambition as presented in the beginning and middle of the class presentations. All about", "confidence": 0.9305607080459595}, {"transcript": " Right, give me an update since for the rest of the class, the art of any kind of endeavor. Like, this is one of the key things that folks. I think learn after you do this a couple times scoping is the magic of success.", "confidence": 0.9011045098304749}, {"transcript": " . Is generalize, has to be honest. Products you Scope.", "confidence": 0.8442139625549316}, {"transcript": " You Scope well, for what your capability, might be your realistic, the realisticness of what you want to set out to do the realisticness of what your team can accomplish the realisticness of what company can you Scope properly, and you will succeed. Most folks. Most of my experiences comes from", "confidence": 0.9504737257957458}, {"transcript": " Scoping. It's an expectation mismatch. Right? Like because then that you can't discourage mind. It's very, it's very subtle thing in such a short time frame. But yeah, that's for sure.", "confidence": 0.8908030986785889}, {"transcript": " Yeah.", "confidence": 0.8488978147506714}, {"transcript": " Interesting. Okay. There's a lot of", "confidence": 0.9820968508720398}, {"transcript": " missed opportunity for true growth because of the anxiety that comes from doing things wrong. You know what I mean?", "confidence": 0.9669620394706726}, {"transcript": " Like,", "confidence": 0.9203842878341675}, {"transcript": " Being being free to try things is part of what learning is. So that's kind of my view that I would love to have. You guys went into is try things, you know, and there's no penalty for learning something. So, usually the right of covers. What is going project? Why is it interesting challenging? Is there any prior work, existing commercially available product that similar to what you do? What's the difference? What are the features functions? How to evaluate the results?", "confidence": 0.9660245776176453}, {"transcript": " This is what they typically look like. I mean, I asked for one page, this group gave me a case of a half, but, you know, I hate people who produced and I just want to capture an essence of what what you present right until this slide deck is available, until we got to see. An example is exactly what a good example of this one pager looks like.", "confidence": 0.9045376777648926}, {"transcript": " Questions questions.", "confidence": 0.7643192410469055}, {"transcript": " Awesome. How many people are a little anxious? Be honest?", "confidence": 0.9468547701835632}, {"transcript": " So, all right.", "confidence": 0.8456724286079407}, {"transcript": " Let's go get us. Some example flies. This may help run it. So this was a group last year. This is Melody conversationally I-4 Spotify. So what is Melody?", "confidence": 0.9094996452331543}, {"transcript": " This is the description of what the project is, Right? Conversational Spotify helper built-in. Alexa. What can it do? Its attack? So basically controlled Advanced playlist, variety of input commands. There's reach goals to accomplish those something even more. Interesting, right? Karaoke mode. Right. Point system on how well you do gamified a bit. Those are very small stones, the tools that they would like to use these always change.", "confidence": 0.9523959755897522}, {"transcript": " This all these changes. So this is a scope of the tools.", "confidence": 0.8689876198768616}, {"transcript": " They show us a bit about what the apis look like that. They that generates the idea. This is a first Approach at at how they're going to design the application.", "confidence": 0.9201260805130005}, {"transcript": " And that was that that was the presentation. Okay. I just always changes this. No getting it right there. This is what we're setting out to do. Okay, and then the Journey of scoping it to something that creates value. At the end of the class. That's an important piece of how to be successful.", "confidence": 0.9347167015075684}, {"transcript": " Another example is onion finder.", "confidence": 0.9095586538314819}, {"transcript": " And problem statement similar. What is it?", "confidence": 0.9210799932479858}, {"transcript": " Bottom line up front.", "confidence": 0.8942241668701172}, {"transcript": " So the kind of features that they wants to accomplish sample, utterances. They threw that. And they gave me, oh, nice stuff there. This is their architecture diagram of how they want to put it together, then. Success Milestones, the related technology summary. That's it.", "confidence": 0.9482060074806213}, {"transcript": " So, these are concrete examples of what this pitch, looks like, okay.", "confidence": 0.9566781520843506}, {"transcript": " All right, any questions?", "confidence": 0.9141162633895874}, {"transcript": " Cool. So this is the first of three presentations about your project in the class. And after the Patch, there is the update, and then there's the final presentation.", "confidence": 0.9248760342597961}, {"transcript": " All right.", "confidence": 0.7126351594924927}, {"transcript": " So we can switch gears 2dn review.", "confidence": 0.951994001865387}, {"transcript": " I feel free to ask questions at any point about what's coming.", "confidence": 0.9224395751953125}, {"transcript": " Okay.", "confidence": 0.9728924036026001}, {"transcript": " So does everyone remember where we left off last time?", "confidence": 0.9485324025154114}, {"transcript": " Good. The three flies that are supposed to paid you back in, but this is the most important one.", "confidence": 0.8775277137756348}, {"transcript": " This is really what a standard.", "confidence": 0.9862081408500671}, {"transcript": " Typical feed-forward neural network. Looks like you've got an input layer. This is where your data touches the model. Then you have a hidden lair.", "confidence": 0.9707549810409546}, {"transcript": " These are weights which each one of these lines represent interact with your summons. Squash that happens in each neuron, write your activation function. And then the signal goes onto the following layer in this case is just three until you have your output after one of those summoned. Squashes, what happens with those summoned splashes is that the strength of the signal that propagates is determined. I think that was a key point that may I made out of emphasize enough, the human brain and so far as when your neurons fire.", "confidence": 0.9556017518043518}, {"transcript": " The strength of that firing is what?", "confidence": 0.9429793357849121}, {"transcript": " Have bearing on whether or not the next neuron in the chain fires, and the next neuron in the chain fires, and that's what's being achieved with that's in here. And then the weights and the mapping it to a line to what the output value looks like, will determine how things are magnified, or", "confidence": 0.9648840427398682}, {"transcript": " Not magnified, at each layer and the likeliness of the firing is where the knowledge is encapsulated much like our brain. Our knowledge is encapsulated in the likeliness neurons. Some combination of neurons will fire and some combination of firing is where the concept of an apple lives in your brain.", "confidence": 0.9592938423156738}, {"transcript": " And that's what we're trying to capture in this. Bring the concept of a 5.", "confidence": 0.9344820380210876}, {"transcript": " 125 looks like lives in the likeliness that signals are sent through the final signals that come out a signal that comes out. It's right.", "confidence": 0.9156246781349182}, {"transcript": " And if it's if you put a 5 in an f45 doesn't come out, it's wrong.", "confidence": 0.8486272096633911}, {"transcript": " All right, and permuting.", "confidence": 0.8494148254394531}, {"transcript": " The weights were changing the values of the parameters, which are like weights excetera in this model weights and biases in this model. So that we get the fire, we want with the day that we know about.", "confidence": 0.9279650449752808}, {"transcript": " Awesome. Any questions on neural networks?", "confidence": 0.9816956520080566}, {"transcript": " All right.", "confidence": 0.7129771709442139}, {"transcript": " So, one of the big questions Venice, how, how do we represent numbers? Represent language as numbers? Right? Cuz it's a picture. I got pixels. This is grayscale. So even nicer every single Pixel is a member. So that's what I'm going to run through my neural network words.", "confidence": 0.8665236830711365}, {"transcript": " Well, let's talk about how we represent words.", "confidence": 0.9700884222984314}, {"transcript": " Do some basic terms for the next few slides, in facts about this the allowable structures in the language. Semantics of the meaning the meaning of what the what the sequence of words and code is important. It's a feature ization that uses a vector of word counts ignoring order. That is if I look in a sentence, I'm going to create a way to view that sentence like a bag of words, just jumbled up. I'm not going to care about the sequences of the world, which seems silly but it seems silly because I use this example a lot. I'm like, if you go to McDonald's and you're like talking to the nurse and they're like", "confidence": 0.9635178446769714}, {"transcript": " With cheeseburger, no, ketchup with ketchup. No cheese. Burger. Same words. A bag of words model is going to look at that as the same thing, but the semantics are wildly different. So that's a little anecdote to illustrate what might be lost with backwards. But bag of words is a very common.", "confidence": 0.9528709053993225}, {"transcript": " Way to Catherine will look at what it looks like. A gram is sequences. So this is actually two addresses backwards thing. So you looking at in the bag of", "confidence": 0.9096322655677795}, {"transcript": " Sequences. So I will look at what that looks like. So that means, I'll take, if you have a two or three bucks each other or the combination of three words, like there's a problem.", "confidence": 0.9377425909042358}, {"transcript": " So, how do we look at what is bag of words?", "confidence": 0.9413553476333618}, {"transcript": " Is every word in the language can have a ID?", "confidence": 0.968982994556427}, {"transcript": " So if you were to put that in an array, let's say English is most have like 500 thousand words or something.", "confidence": 0.83292555809021}, {"transcript": " Pregnant from wrong. Just being a real, 500,000 Elementary, not a real. Every number number two in a Terrain my top and be the work orange. So you can represent all of the words in the language of the Giant.", "confidence": 0.9160412549972534}, {"transcript": " Mapping of word to ID large.", "confidence": 0.9135806560516357}, {"transcript": " So when you do that, here's what it looks like.", "confidence": 0.9780484437942505}, {"transcript": " You'll have a sentence, the cat sat on the map right now that we have our 5000.", "confidence": 0.8080225586891174}, {"transcript": " Element Factor on every of those words has an ID in the vector or a location. You guys think of the index as an ID for this example, and then you just see a sequence of IDs.", "confidence": 0.9474966526031494}, {"transcript": " So, you can just map words, you can get a string of words and then just see a sequence of ideas when you use this.", "confidence": 0.9661949276924133}, {"transcript": " Dictionary base bag of words approach.", "confidence": 0.9064226746559143}, {"transcript": " So, this is how we bag of words in, so you can take.", "confidence": 0.9484085440635681}, {"transcript": " The sentence, right? And then", "confidence": 0.9581499099731445}, {"transcript": " in your vector, that is the size of 500,000. You have a vector to represent the sentence.", "confidence": 0.9442659020423889}, {"transcript": " So, the whole whatever sentence you have, you have a 500000 Factor?", "confidence": 0.8982409834861755}, {"transcript": " That has a count of.", "confidence": 0.9543238878250122}, {"transcript": " How many of that word appears? So if your first element is, duh?", "confidence": 0.9529004693031311}, {"transcript": " You'll have two of them, right? I meant cat. You have one cat 0001 that one on and then one more. So here you can you can represent that sentence or any sentence, or any string of tax would have 500,000 word Vector, 500,000 element Vector, where the position and Vector that corresponds to the word. Just has a count of how many words are present in your bag.", "confidence": 0.935995876789093}, {"transcript": " Duffle bag of words.", "confidence": 0.7221845388412476}, {"transcript": " Feature ization. So you would just store it like every word idea. How many there are for the ones that have weird ideas, right? There's a lot of details, what I'm presenting here is the journey that gets us to", "confidence": 0.9476237297058105}, {"transcript": " How we do it today? Right? This is just some of the foundational pieces. You can have a bag of words, way of capturing the, a piece of text where you're just counting the occurrence of each word in that text, and you're representing it as a sparse Vector. In this case or as a", "confidence": 0.958036482334137}, {"transcript": " Now with that, you can do the same with any grams, right? Because you don't like to lose the ordering.", "confidence": 0.9472963213920593}, {"transcript": " so, an engram is", "confidence": 0.9059097766876221}, {"transcript": " We're going to, instead of using each word has an ID, you can say each combination of word.", "confidence": 0.9720104932785034}, {"transcript": " Has an ID, right?", "confidence": 0.6781772375106812}, {"transcript": " So, the cat has one element. Has another element on the map, right? That's a two.", "confidence": 0.9431124925613403}, {"transcript": " so, you have a much bigger Factor because you're doing,", "confidence": 0.9449259042739868}, {"transcript": " then you have a unique ID for every", "confidence": 0.9666857123374939}, {"transcript": " Purple of words that come in a sequence of the combination. But whenever you see an engram with an being tour, ending 3 and you always see it like less than five. That's because of the complexity that comes when you have large end, you can represent it. This is what that representation means. Okay, so that bag of words,", "confidence": 0.9513186812400818}, {"transcript": " Backwards and engrams. Okay. Now you can do all kinds of cool stuff. You represent your sentence. You can actually do a combination as a representation because then that combination and codes a little bit more information. Right? Not only do you see what words are in there, but you can kind of see the two grams in there under three grand. I didn't you can actually have more complex, more beefy ways to represent that text until this is this is how you'll see whenever you see engrams or bag of words in literature. That's what they're talking about. It's a way of representing things.", "confidence": 0.9582632780075073}, {"transcript": " With those kinds of those kinds of representations, one gram backwards and I can see that I have 17 Fantasticks and one terrible in there the neural network and say all day and probably a very happy happy face. But if I see the opposite 17 Terrible's and one fantastic, then the morgue to use the encoding and a problem is if you say something like", "confidence": 0.9368122220039368}, {"transcript": " This is why you need to Gramps. If you say this is stupid Lisa and this is stupidly fantastic. Or you can say this is stupid, right? You might need that too because that's just one one. It'll say it's neutral, but it's actually one way or the other.", "confidence": 0.9283081293106079}, {"transcript": " So so that's so we're just talking about that topic. Taking words and representing it in a way that a model can understand it in the useful way.", "confidence": 0.9068015813827515}, {"transcript": " Yeah, okay, follow the power law of course, right? So that means that this can be much more common to grams and rare or two grams. You're going to see in a sentence.", "confidence": 0.8780337572097778}, {"transcript": " I don't know, like", "confidence": 0.950713038444519}, {"transcript": " Bicycle.", "confidence": 0.9123563170433044}, {"transcript": " Newtonian physics, why you're not going to see that. So that's a tree that will never appear. Right? And there's actually way more three grams that will never appear in the language than there are three friends that will appear in the language. So luckily you don't have to store all of it is getting into those things. Right? And so I cut this short because honestly not, you know what it is. How many people feel like? They know what a bag of words in a engram is feel you.", "confidence": 0.9425461292266846}, {"transcript": " By the way, just count the occurrences of unique words, in your sentence and an engram, count the unique and combos of words in your sentence into a numerical representation that you can use in a model to train it.", "confidence": 0.9427624940872192}, {"transcript": " In a very basic. This is basic thing that we can actually do with deep learning. This is like where it started. And actually the first paper, you're going to read this right now because it's called one hot encoding. So instead of looking at it as integers. Just think of it as binary, right? So essentially", "confidence": 0.9271972179412842}, {"transcript": " You take the sentence and then you turn each word into their.", "confidence": 0.8798640370368958}, {"transcript": " Vector. And then you have a sequence of those factors. Right, man, bites, dog. Let's say this is your whole vocabulary, your whole language, not a very expressive language, but that's all the words in the language than that distance. Looks like this sequence. So you have three vectors a vector for each sentence and it's dog One Bites to man, The Third", "confidence": 0.9214592576026917}, {"transcript": " And it's not see a picture from the first paper.", "confidence": 0.771654486656189}, {"transcript": " There's something called. This is an example of how it goes through a network. Okay, so we're going to talk about this. Not work later, but I'm just going to share an example in coding.", "confidence": 0.8668673038482666}, {"transcript": " Then you can take the sequence word, T-minus 1 TV in the word, you're on.", "confidence": 0.8138535022735596}, {"transcript": " Spell the word you're on, you can take two words before it into words after it.", "confidence": 0.866194486618042}, {"transcript": " And you can run those as an input. It's a window of for right, well, window size to 2 before 2, after you take those words, these four words.", "confidence": 0.9294687509536743}, {"transcript": " Continuous bag of words, what it does is it predicts? What word should be in the middle of your sequence of words spring pool problem.", "confidence": 0.9262697696685791}, {"transcript": " There's so much to talk about this. Like, I can get off track. What? I'm just trying to show you, but what I'm trying to show you is.", "confidence": 0.9204128384590149}, {"transcript": " You're one hot and cold your words. Go in as those vectors would have one on which word it is. I'm done. You can train a neural, not not work to do something useful. So the word that comes out is going to be also add one hot encoding that encodes the predicted word. Right? So see if I was a problem of taking, those windows of the cat on floor and predicting. What's that? Middle word self esteem by works on.", "confidence": 0.92303866147995}, {"transcript": " I'm so when those words go in. You've got some news on that, work learning that's going to Output the encoding for sat, right?", "confidence": 0.8802086710929871}, {"transcript": " Is that?", "confidence": 0.8962092399597168}, {"transcript": " Clear.", "confidence": 0.8478652238845825}, {"transcript": " All right. This is a cool model of the reason why I'm going to die because they decide I don't have to get a whole bunch of forwards and then label the right where to go in. In the middle. I can literally just say, take this structure and go read Wikipedia because I've got an incredible amount of sequence. Real language that in an unsupervised, way. I can just March along the the text. I need to just look at the words and saying all these are the two of them. That's the middle, and it's training itself to predict that, right. So that works in in length in language and it's actually incredibly powerful.", "confidence": 0.9491175413131714}, {"transcript": " Oh, yeah. Yeah, don't totally totally do supervised. Learning means.", "confidence": 0.9275084733963013}, {"transcript": " If I would do it, if I was going to take this model in training and supervised way.", "confidence": 0.9483349919319153}, {"transcript": " Imma have to prepare a dataset. I might have to go and create one and an established truth and I would have an expert would have to do that. So I'll supervise person would have to do that or would have to do that. I didn't give it to date. It's laborious right? Cuz", "confidence": 0.9512218832969666}, {"transcript": " Did the Bronx with those two? What? What it should predict as a little more crap, so and the prediction I'll put I'll just have to give it examples and if you have to manually do that, then it's supervised learning. But if you could just let a model, if you can configure a model in such a way that I can just go, look at unstructured data and learn on its own. They call them unsupervised, learning. So", "confidence": 0.9519475698471069}, {"transcript": " Yeah, yeah. So what did end up learning is in this particular case? And then I'll talk about Superman Spider-Man but in this particular case, what it's learning is.", "confidence": 0.9342048764228821}, {"transcript": " The ability to predict the output, the one hot and coding for the word that should be in the middle of those inputs. Right? So it sees this as the input in the wild, right? When you want to listen to Cheese's and put on, it's making a prediction as to what's the word that should be in the middle.", "confidence": 0.945440948009491}, {"transcript": " And that means that when these numbers go in and just to be 1000, 11001 excetera when those numbers go in the way, the weights are configured and wavy activation function work in the weights here. It'll output 101 which is that, right. So we actually need to get this not work to have knowledge. We actually going to cost us of all these so that we get the thing that we want out here that there's right. I'm in getting it to do that.", "confidence": 0.9292020797729492}, {"transcript": " It doesn't do do it like crazy ways. Like that's where it's a learned model which is which is so cool.", "confidence": 0.8789714574813843}, {"transcript": " A lot of folks don't understand really why that works on how they don't understand the parameters of the limits to how much that can work. And it's not a deterministic thing that we can do. You write me measure? How well it works. That's my machine learning. So empirical it such an empirical science cuz somebody might change a rule.", "confidence": 0.9244807362556458}, {"transcript": " Do if someone said that they would know if it's better or worse, unless it's Friday. And that's a dozen very kind of beautiful thing about this discovery. But yeah, that's the explanation and soul.", "confidence": 0.888461709022522}, {"transcript": " In the pixel landscape, let's think of the pixel. Example, supervised learning is I got to go get pictures of Batman and Superman and then I'm going to give it to the model.", "confidence": 0.9772241711616516}, {"transcript": " Right, and then I'll tell it that and then I expect the model to be able to see and recognize he will enter Batman.", "confidence": 0.8969811797142029}, {"transcript": " That's a supervisor training an unsupervised approach if you if one could be constructed, is I never given any data. I just set it up and I say go off into the world and learn, you know, into this world and learn what to run by my looks like a man.", "confidence": 0.9326130747795105}, {"transcript": " I'm indeed. I'm not aware of any image. Classification models that learn in an unsupervised way. I'm not familiar with it. No, actually I am but that would be don't get on supervised mean and I thought I was right now on unsupervised, way to train an image model, would be to say, go read all the web pages on the internet and I'm going to let you assume that the text around the images correspond to the images and I will get on supervised mean. So I don't have to go and prepare a dataset. I'm just going to let this model go and read the internet and then it should come back and say I can recognize a fats and dogs and planes, because I'm not the internet and I looked at the image and then I looked at the text around it and I built a representation of that, and now I'm good at that. So that would be a good example of an unsupervised.", "confidence": 0.9627379179000854}, {"transcript": " Shredded papers about it, like, check it out.", "confidence": 0.9040337204933167}, {"transcript": " Nobody know, but two, that's one. I'm here to talk about this because it's so it's so crazy. So this is one and this is our first day for it's worth of that and that's actually be paper that changed our world from a commercial standpoint where to buy for the first Juggernaut. That was like just the way we should be doing natural language processing. So we talk about ideas how to train these models in this way and I made a big splash but it turns out the hunting setup.", "confidence": 0.9453572630882263}, {"transcript": " The Stuck in the Middle, hear that you get after you train it on this problem and the being really useful for other things, right? I'm going to look at how you can translate the learning, the new problems and it's super smart and the new problem. We're going to look at it. You know, if you take King Midas Queen, you got Prince or something like you, do math on birds, like you could subtract will get there, but the knowledge in here, becomes really useful for a whole bunch of other things. And I don't feel we're going to talk about that.", "confidence": 0.9424521923065186}, {"transcript": " I'm not the symbol this a sibo formulation to get the knowledge in here. I'm going to cram knowledge in the middle by training it to solve this problem. You can set up other problems, other models, right? So you can say you know, what model, I want you to look at the sentence and then predict the next sentence. It's a different one and it's a different construction to Primm model into the knowledge into the model with a different problem. Solving. It's using the same day to sight in a different way. I'm in Maine create more knowledge or less knowledge. 21 is I'm going to take a model like this and I want to take sentences of randomly randomize a word.", "confidence": 0.9741901159286499}, {"transcript": " I'm going to randomly replace a word in the sentence. And I'm going to train this model to predict which word was randomly changed. That was the Burt Innovation. That was one of them birthday to things that didn't add up the masking, which is I'm going to randomly change the word and I'm going to let you predict what it is.", "confidence": 0.9338071942329407}, {"transcript": " I'd like the problem.", "confidence": 0.7863589525222778}, {"transcript": " Prim's knowledge in here in a few. Crazy. You'll see it will look at it deeply and then it's another picture of the same stuff. You've got that one hot and coating. Of course, this in the simplified cases like 500.", "confidence": 0.9265103340148926}, {"transcript": " 500 100. Then there's only one one in. It is crazy. I know you train it so that you get the fat as the output. And then this hidden Lair, is what this is, your embeddings.", "confidence": 0.8569356799125671}, {"transcript": " Which is what creates these this representation for other stuff. That's not how this stuff works for the drawbacks to 100. This, this particular way of representing language, one hot and coding does drawbacks input backers are large island is out of vocabulary. So if there's like a new word like LMFAO or whatever, right? And you see it in your texts, you may not have a thin coating for you. Can't really utilize it and see what they do is they just inject unknown.", "confidence": 0.9409085512161255}, {"transcript": " For where is it doesn't see? And then it has an incoming phone on. This is a little weird but not the drawback in the knowledge, that one hot and coding can get", "confidence": 0.8513389825820923}, {"transcript": " Right under the Regatta. This is actually really important. There's no relationship. Like like there's no relationship between the word and the number. The number is just", "confidence": 0.9017454981803894}, {"transcript": " in your array, whichever one of those bits are hot, right? Or 1. I know you know, you might have a 1", "confidence": 0.8809471726417542}, {"transcript": " At the first number that and that could be like cat. And then as to never give your refrigerator and there's like, no relationship between the encoding. So that's a drawback and we're going to look at what happens when you can get richer.", "confidence": 0.9203493595123291}, {"transcript": " Representations. Because actually, what we'll end up doing is using the product of hidden layers to be the representation, which creates this magical stuff that we're going to work and back paper.", "confidence": 0.9106375575065613}, {"transcript": " So ideally we want relation between word back to us or a flag relation between words and features of word of word embeddings to reflect features of words. So you want to be able to if you can have a way like we have that in the English language a good way to describe. This is actually don't think of a good way.", "confidence": 0.9328402876853943}, {"transcript": " Okay, like like for instance, a word like funk.", "confidence": 0.956989586353302}, {"transcript": " Right. There's actually a higher level. It's not just a random word. It's like it kind of sounds like Funk Funk. So word means almost audibly what it is. So there we have a higher level value to the what the structure of the word is that is helpful. Slam may be the number one, Eureka.", "confidence": 0.9088937640190125}, {"transcript": " I don't know where that might be really good for that.", "confidence": 0.8698545694351196}, {"transcript": " Yeah, yeah. Yeah, that's actually funny thing about, sorry. This is actually just kind of reiterating.", "confidence": 0.9287413954734802}, {"transcript": " This is actually a hint, right? Cuz you can get based on the weights.", "confidence": 0.9832633137702942}, {"transcript": " That are coming out.", "confidence": 0.7345901131629944}, {"transcript": " You can actually get away to represent words.", "confidence": 0.954411506652832}, {"transcript": " On the, on the way to produce after the models trained, right? So you can take a hidden layers output and have that heavy layers output produce a sequence of numbers that represents the word. That would be the input and then you can get something that you can do the lies and interesting ways. There's a little bit of a pre pre a little hint of what's to come. When we look at the stuff more deeply.", "confidence": 0.952912449836731}, {"transcript": " So we got a couple more minutes. Bear with me while. I give a little preview of what the come of where we're heading, right?", "confidence": 0.9728344082832336}, {"transcript": " so,", "confidence": 0.8860746622085571}, {"transcript": " If you were to have this representation, that wasn't one hot anymore, I train the model.", "confidence": 0.9327221512794495}, {"transcript": " That takes in one hot and Coatings and outputs something that might mean something because I just crammed a bunch of knowledge in the middle of this model and now I can take advantage of whatever I traded with him. Let's artificial problem that captures meeting. I'm just a creative. This is how the researchers did and they're like, I'm a creative person. We got all the data. I know they're just like the corn meaning of this data and cram it into a model.", "confidence": 0.9468105435371399}, {"transcript": " I want to see what it was. Like, you know, what, if I can predict the middle. I don't know how they can be. The model. Will know something. If I can randomly change words and then predict which one was change name to model? Them know, something about our language. If I can predict the next time you give me a sentence from the depths that right in the middle of the mall in like know something. Deep about the language has a problem like that and then I get the lyrics to produce these weights to introduce this representation of a word.", "confidence": 0.9510382413864136}, {"transcript": " Now, look at that, dude. This is one of those creative things in the on the planet that led to work of act, right? And that's where we're going to look at.", "confidence": 0.9217504858970642}, {"transcript": " Maybe we can get such a representation that if you were to look at the Clusters.", "confidence": 0.9659746289253235}, {"transcript": " You would see similarities like yeah, apple and orange should be close to each other and bus and Country Angels related. That's interesting that you know, you got the traditional bag of silliness. We talked about this boring but a numerical representation that can stories word in a point of space were represented by a vector generate 300. It's on supervised.", "confidence": 0.9589791893959045}, {"transcript": " We'll get to the math, please. This is. Yeah, that's how it works. But maybe you can get like, interesting relationships like this represented in the space, right? Like", "confidence": 0.9177836775779724}, {"transcript": " You know, if you take King and subtract Coon, you may get mad. And if you think we need some tracking, you got woman and, you know, you might be able to have these interesting numerical relationships expressible, right? Like a country to its capital might have the same.", "confidence": 0.9417213797569275}, {"transcript": " Almost mathematical difference. So if I if I took Spain in Madrid,", "confidence": 0.950581967830658}, {"transcript": " Subtracted. The difference between freedom and read and added it to Italy. Maybe I'll go close to Rome.", "confidence": 0.8907312750816345}, {"transcript": " So I'm like so how is that subtraction? I'm capturing what it is to be a capital. This is just an emergency out of cramming stuff in the middle of the magic. That's the crazy. That's right. Right. And all kinds of weird things with these models that just seems like like Skynet AI. So you can do machine translation with those kind of methods. You can do parts of speech tag in with that kind of methodology.", "confidence": 0.9210193157196045}, {"transcript": " Relationship extraction. This is what we talked about it. But you know, big bigger, Miami, Florida, Einstein scientist. You can actually capture relationships and then infer on the analogous relationship. Right? Like, you know Einstein the scientist has been going to artist right? Like you might as well go is kind of like what science is the thing and then you'll see what its losses for Vango you do sentiment analysis, right?", "confidence": 0.9194781184196472}, {"transcript": " Within this or unsupervised way in read a bunch of texts. It just read a bunch of texts. No one trained in anything, and he said, what's a lot like that? And then it's like a sad. Meaning, sad, heartbroken disheartening.", "confidence": 0.9117243885993958}, {"transcript": " Some of the stuff I may be that there was a really sad people saddens me distressing. Reminders bobbing interesting, magic regretful Bittersweet. And just told you that all that stuff is very close to sad, and that's kind of cool because you didn't do anything. Other than said, hey model, go read, Wikipedia and look at what the middle word is. And now I know this. And that's the magic of the first paper. We're going to look at which is all about.", "confidence": 0.9596301317214966}, {"transcript": " Define feeble.", "confidence": 0.5217671394348145}, {"transcript": " Doing this on Wikipedia.", "confidence": 0.9793722629547119}, {"transcript": " Call three-time Laughing. 7 Minutes questions.", "confidence": 0.832990825176239}, {"transcript": " I think that are for true because similar words are used in similar contact.", "confidence": 0.6866226196289062}, {"transcript": " You might say that.", "confidence": 0.7657499313354492}, {"transcript": " Just kidding cast.", "confidence": 0.4211066961288452}, {"transcript": " Chase's place. Where is dog? Plays Fetch. And that's a wonderful question. And the way the way the best answer I have in the way that I've heard people describe it is, it's a multidimensional space. What we've been looking at are really simplified two-dimensional kind of things, right? That's not too much space. So", "confidence": 0.944560706615448}, {"transcript": " the number of Dimensions can give you a capacity for the amount of relationships that can be captured almost right because Kevin dog might be closed as nouns and objects, but maybe cat chases is closed, you know, like you'd expect to see a cop chase, you know what I mean more than escape and so that could be captured or maybe Kat and", "confidence": 0.9536924362182617}, {"transcript": " I don't know cat like as a slang word to be like, oh, that's a cool cat. I don't, I don't know, right? Like what you might need to capture that too. In the one representation that the width of the dimensions that that kind of has bearing on the capacity of how much relationship you can model. It's much. Like you can think about mapping that to a linear Dimension. Where is a cat to be five in a dog to be 17. You can't, you can't not as many relationships between those in a low dimensional space but in high dimensional space across some Dimension. You may be able to capture one relationship and it goes. It's it's kind of like so there is a capacity to how much knowledge you can capture.", "confidence": 0.9447845816612244}, {"transcript": " Another properties is how deep in the layers. Is the best layer to extract for your problem.", "confidence": 0.9383488893508911}, {"transcript": " So, your question is, is a good one? And the real answer is.", "confidence": 0.9269134998321533}, {"transcript": " Folks, don't necessarily know what captured in those representations. They tried some things and noticed, some interesting relationships that he merge like well, what's the distance of a word? Oh, it's a movie similar given that dataset but there's actually a new kinds of realizations. Right? Like like 53 actually kind of work like this. It's a different problem, but it just learn some silly unrelated thing to criminologist.", "confidence": 0.9534336924552917}, {"transcript": " They didn't know that being able to talk code like me. I'm to describe code and it'll write code is a possibility and then it can also answer multiple-choice questions and then it can also generate news articles that look realistic. It's like it's doing all of these other things in that model. There's there's things caption that we don't fully understand and we don't even know what the bottles are in an actual because you can't measure it but this is some of the principles, right? You're you're capturing relationship with dimensionality and this into a relationship between the dimensions that end up mattering to write and no one knows what it is.", "confidence": 0.9509153366088867}, {"transcript": " Do you think the relationship between?", "confidence": 0.7357757687568665}, {"transcript": " Directions to me.", "confidence": 0.42400631308555603}, {"transcript": " I don't know. Something like other animals trailer.", "confidence": 0.7637426853179932}, {"transcript": " I can write this is great. That's a great question. Is related, because it learns from the data you give it. That's the key thing. Right? So, if you were to take, you didn't use Wikipedia, I knew used, I don't know like film Scripts.", "confidence": 0.9212068319320679}, {"transcript": " Cat may not have anything to do with dogs, wanted learns, these relationships from that data sent. So so insofar as it's not right. It's it's it's whatever knowledge could be produced from the dataset given and that particular problem, right? That was the final word is a problem. Cibao is the problem. So the combination of that problem, Plus data Surplus capacity of the model produces the actual in learning in a deterministic way, but you can change any of those variables and get weaker or stronger links across different dimensions.", "confidence": 0.9661805629730225}, {"transcript": " So if I was to instead of use the word in the middle, what if I use the next word, right? And I just trained the model and predicting what the next word is.", "confidence": 0.9373955130577087}, {"transcript": " You may not get cat and dog being similar, right? Cuz dogs might always go to fights and taught all of those scratches, right? So, so, then your dog and cat might be very different, right? Because now cat is associated to chairs that scratch. The floor and dogs are associated to babies who bite the your binky or whatever, right? I meant. So you might get out, so, I can change the problem that it's using two on the same data. You can get completely different representation, but the middle word, t-ball, I would, I would ask you can replace cat and dog in the middle of a sentence.", "confidence": 0.9607861042022705}, {"transcript": " The cat ran really fast. The dog ran really fast, right? Like it's more replaceable. So that one captures that nature of relationship better and it's an art form. Like the guy doesn't see what it produces see, what useful intelligence is are produced from from these endeavours the train.", "confidence": 0.9292281866073608}, {"transcript": " Exactly.", "confidence": 1.0}, {"transcript": " Right, right. That's a good point. Total in the paper. There's two, there's cibao, which is predicting the middle word and then to skip ground which is taking just the word in predicting. The outer words does the direct opposite. Let me predict the forwards next to me cuz I'm my work and a paper shows that see if it works better for the things they like but there was one or two things work better for. It's just the nature of of of the problem that you give the model. It'll determine what kind of hidden knowledge does the model. Gosh. That's the best I can do to. I know it's not fully satisfying. You want to explain it, but it's magic. Awesome.", "confidence": 0.9439867734909058}, {"transcript": " I'll see you guys Wednesday.", "confidence": 0.9815943837165833}, {"transcript": " And anyone who's anxious about next week come talk to me, please. I will talk through it. We'll figure it out together team.", "confidence": 0.898747980594635}, {"transcript": " All right.", "confidence": 0.7128972411155701}, {"transcript": " Cool.", "confidence": 0.9848019480705261}, {"transcript": " Hey.", "confidence": 0.7867373824119568}, {"transcript": " I have a sister.", "confidence": 0.7455233335494995}, {"transcript": " Unfortunately, I have no physical therapy to work.", "confidence": 0.7379473447799683}, {"transcript": " I'm glad you're doing good.", "confidence": 0.7439233660697937}, {"transcript": " Brenda I'll be missing you. Can we find contribute? As long as you contribute, some presentation like offline and we can accommodate any time? Yeah, I know, right? I mean last time I just rented it. So so participation often gives an opportunity for folks who might miss something, then I can kind of pay attention to whether they were parts of the participating in practice. It's kind of a group was saying and it's very difficult.", "confidence": 0.9625377058982849}, {"transcript": " Subtract from a tactical.", "confidence": 0.8595160245895386}], "speakers": []}