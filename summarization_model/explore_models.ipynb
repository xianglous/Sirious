{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Explore models\n",
    "Try SOTA text summarization models for their performance on speech/lecture transcripts\n",
    "Since Sat. Oct. 23rd, 2021\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(get_1st_n_words(txt_ted, as_arr=True)): 3130\n",
      "ic| len(get_1st_n_words(txt_498, as_arr=True)): 10548\n"
     ]
    },
    {
     "data": {
      "text/plain": "10548"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setup\n",
    "import torch\n",
    "# import tensorflow\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import PegasusTokenizer, BigBirdPegasusForConditionalGeneration, BigBirdPegasusConfig\n",
    "\n",
    "from util import *\n",
    "\n",
    "\n",
    "txt_ted = get_ted_eg()\n",
    "ic(len(get_1st_n_words(txt_ted, as_arr=True)))\n",
    "txt_498 = get_498_eg()\n",
    "ic(len(get_1st_n_words(txt_498, as_arr=True)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BigBird\n",
    "\"Big Bird: Transformers for Longer Sequences\".\n",
    "Manzil Zaheer, Guru Guruganesh, Kumar Avinava Dubey, Joshua Ainslie, Chris Alberti, Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, Amr Ahmed.\n",
    "*NeurIPS 2020*.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| txt_498[:400]: (\"No, you don't need a reason. Apple TV. All right. Apple TV. Sweet don't have \"\n",
      "                    \"to carry around a dongle. Welcome, welcome everybody. Yeah, it's um the \"\n",
      "                    \"gloomy day. I got a bunch of great emails saying I can't make it. I feel it. \"\n",
      "                    \"I feel it. But anyway, let's just jump right into how many people have \"\n",
      "                    \"groups? Awesome. That's all you left. The scene. Pretty much everybody. So \"\n",
      "                    \"we'll will tease out who mad\")\n",
      "/Users/stefanh/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:790: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/76/fm8fgr4n1p78whqg7x_bd5480000gn/T/ipykernel_6291/2611116698.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[0;31m# txt = get_1st_n_words(txt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;31m# ic(txt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 37\u001B[0;31m \u001B[0mic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbigbird_pegasus\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtxt_ted\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     38\u001B[0m \u001B[0mic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbigbird_pegasus\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtxt_498\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/76/fm8fgr4n1p78whqg7x_bd5480000gn/T/ipykernel_6291/2611116698.py\u001B[0m in \u001B[0;36mbigbird_pegasus\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPegasusTokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'google/bigbird-pegasus-large-arxiv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_length\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m4096\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_tensors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'pt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtruncation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m     \u001B[0msummary_ids\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'input_ids'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_beams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_length\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m256\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mearly_stopping\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msummary_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \"\"\"\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001B[0m in \u001B[0;36mdecorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdecorate_context\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/generation_utils.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001B[0m\n\u001B[1;32m    920\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_encoder_decoder\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    921\u001B[0m             \u001B[0;31m# add encoder_outputs to model_kwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 922\u001B[0;31m             \u001B[0mmodel_kwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_prepare_encoder_decoder_kwargs_for_generation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    923\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    924\u001B[0m             \u001B[0;31m# set input_ids as decoder_input_ids\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/generation_utils.py\u001B[0m in \u001B[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001B[0;34m(self, input_ids, model_kwargs)\u001B[0m\n\u001B[1;32m    415\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0margument\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"decoder_\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0margument\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"cross_attn\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    416\u001B[0m             }\n\u001B[0;32m--> 417\u001B[0;31m             \u001B[0mmodel_kwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"encoder_outputs\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mModelOutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mencoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mencoder_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    418\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mmodel_kwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1921\u001B[0m                     )\n\u001B[1;32m   1922\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1923\u001B[0;31m                     layer_outputs = encoder_layer(\n\u001B[0m\u001B[1;32m   1924\u001B[0m                         \u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1925\u001B[0m                         \u001B[0mattention_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, hidden_states, attention_mask, layer_head_mask, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, output_attentions)\u001B[0m\n\u001B[1;32m   1391\u001B[0m         \u001B[0mresidual\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhidden_states\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1392\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinal_layer_norm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1393\u001B[0;31m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactivation_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfc1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1394\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1395\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfc2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1846\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1847\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1848\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1850\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def bigbird(text):\n",
    "    \"\"\"\n",
    "    `BigBird` in torch\n",
    "\n",
    "    Looks like doesn't support summarization\n",
    "    \"\"\"\n",
    "    summarizer = pipeline(\n",
    "        'summarization',\n",
    "        model='google/bigbird-roberta-base',\n",
    "        tokenizer='google/bigbird-roberta-base'\n",
    "    )\n",
    "    summarizer(text, min_length=5, max_length=20)\n",
    "# bigbird('hello world')\n",
    "\n",
    "\n",
    "def bigbird_pegasus(text):\n",
    "    model = BigBirdPegasusForConditionalGeneration.from_pretrained('google/bigbird-pegasus-large-arxiv')\n",
    "    tokenizer = PegasusTokenizer.from_pretrained('google/bigbird-pegasus-large-arxiv')\n",
    "    inputs = tokenizer([text], max_length=4096 * 2, return_tensors='pt', truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=256, early_stopping=True)\n",
    "    return tokenizer.batch_decode(summary_ids)\n",
    "\"\"\"\n",
    "Hyper-parameter seems to affect the result drastically\n",
    "\n",
    "On TED.com `Do schools kill creativity?`\n",
    "'<s> we present a brief discussion of the nature of education in the era of '\n",
    "'big data and big rip.<n> we start with a brief history of education in the '\n",
    "'era of big rip.<n> we then turn to a brief discussion of the nature of '\n",
    "'education in the era of big rip.<n> we conclude with a discussion of the '\n",
    "'future of education.'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ic(txt_498[:400])\n",
    "# txt = get_1st_n_words(txt)\n",
    "# ic(txt)\n",
    "ic(bigbird_pegasus(txt_ted))\n",
    "ic(bigbird_pegasus(txt_498))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## T5\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c0af65b3a4749f7885989ec4c0ee3e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f2ff65135984c91be6afe32b74fc2db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb4462fc17a14c8f822201426534df5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.74k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09691a4dad1d43df808a318d8fae00d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "\nT5Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\nthat match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/76/fm8fgr4n1p78whqg7x_bd5480000gn/T/ipykernel_6291/3677326039.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAutoTokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"mrm8488/t5-base-finetuned-summarize-news\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAutoModelWithLMHead\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"mrm8488/t5-base-finetuned-summarize-news\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0msummarize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_length\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m150\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    496\u001B[0m             \u001B[0mtokenizer_class_py\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokenizer_class_fast\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTOKENIZER_MAPPING\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    497\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtokenizer_class_fast\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0muse_fast\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mtokenizer_class_py\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 498\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mtokenizer_class_fast\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpretrained_model_name_or_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    499\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    500\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mtokenizer_class_py\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   1741\u001B[0m                 \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"loading file {file_path} from cache at {resolved_vocab_files[file_id]}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1743\u001B[0;31m         return cls._from_pretrained(\n\u001B[0m\u001B[1;32m   1744\u001B[0m             \u001B[0mresolved_vocab_files\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1745\u001B[0m             \u001B[0mpretrained_model_name_or_path\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001B[0m in \u001B[0;36m_from_pretrained\u001B[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, *init_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   1869\u001B[0m         \u001B[0;31m# Instantiate tokenizer.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1870\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1871\u001B[0;31m             \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minit_inputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0minit_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1872\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1873\u001B[0m             raise OSError(\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, vocab_file, tokenizer_file, eos_token, unk_token, pad_token, extra_ids, additional_special_tokens, **kwargs)\u001B[0m\n\u001B[1;32m    126\u001B[0m                 )\n\u001B[1;32m    127\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 128\u001B[0;31m         super().__init__(\n\u001B[0m\u001B[1;32m    129\u001B[0m             \u001B[0mvocab_file\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    130\u001B[0m             \u001B[0mtokenizer_file\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtokenizer_file\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mslow_tokenizer\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m             \u001B[0;31m# We need to convert a slow tokenizer to build the backend\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m             \u001B[0mfast_tokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_slow_tokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mslow_tokenizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mslow_tokenizer_class\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m             \u001B[0;31m# We need to create and convert a slow tokenizer to build the backend\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py\u001B[0m in \u001B[0;36mconvert_slow_tokenizer\u001B[0;34m(transformer_tokenizer)\u001B[0m\n\u001B[1;32m    961\u001B[0m     \u001B[0mconverter_class\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSLOW_TO_FAST_CONVERTERS\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtokenizer_class_name\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    962\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 963\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mconverter_class\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtransformer_tokenizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mSpmConverter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mConverter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    420\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 421\u001B[0;31m         \u001B[0mrequires_backends\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"protobuf\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    422\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    423\u001B[0m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/UMich/Development/Team Sirious/Sirious-Assistant/venv/lib/python3.9/site-packages/transformers/file_utils.py\u001B[0m in \u001B[0;36mrequires_backends\u001B[0;34m(obj, backends)\u001B[0m\n\u001B[1;32m    681\u001B[0m     \u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"__name__\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    682\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBACKENDS_MAPPING\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mbackend\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mbackend\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbackends\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 683\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mBACKENDS_MAPPING\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mbackend\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mbackend\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mbackends\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    684\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    685\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: \nT5Converter requires the protobuf library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones\nthat match your environment.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-summarize-news\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-summarize-news\")\n",
    "\n",
    "\n",
    "def summarize(text, max_length=150):\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    generated_ids = model.generate(input_ids=input_ids, num_beams=2, max_length=max_length,  repetition_penalty=2.5, length_penalty=1.0, early_stopping=True)\n",
    "    preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "    return preds[0]\n",
    "\n",
    "\n",
    "text = get_ted_eg()\n",
    "ic(summarize(text))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}